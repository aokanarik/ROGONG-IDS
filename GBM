{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229a362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn import under_sampling, over_sampling, combine\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0007ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data\n",
    "\n",
    "path = '/Users/ahmetokanarik/Desktop/MScThesis/Dataset/UNSQ-NB15'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename,header=None,sep=';',low_memory=False, nrows=78000)\n",
    "    li.append(df)\n",
    "\n",
    "\n",
    "data = pd.concat(li, axis=0, ignore_index=True)\n",
    "data.columns = [\"srcip\",\"sport\",\"dstip\",\"dsport\",\"proto\",\"state\",\"dur\",\"sbytes\",\"dbytes\",\"sttl\",\"dttl\",\"sloss\",\"dloss\",\"service\",\"Sload\",\"Dload\",\"Spkts\",\"Dpkts\",\"swin\",\"dwin\",\"stcpb\",\"dtcpb\",\"smeansz\",\"dmeansz\",\"trans_depth\",\"res_bdy_len\",\"Sjit\",\"Djit\",\"Stime\",\"Ltime\",\"Sintpkt\",\"Dintpkt\",\"tcprtt\",\"synack\",\"ackdat\",\"is_sm_ips_ports\",\"ct_state_ttl\",\"ct_flw_http_mthd\",\"is_ftp_login\",\"ct_ftp_cmd\",\"ct_srv_src\",\"ct_srv_dst\",\"ct_dst_ltm\",\"ct_src_ ltm\",\"ct_src_dport_ltm\",\"ct_dst_sport_ltm\",\"ct_dst_src_ltm\",\"attack_cat\",\"Label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219e00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "dummies = pd.get_dummies(data[['service','proto','state']])\n",
    "data.drop(['proto','service','state'],axis=1,inplace=True)\n",
    "data = pd.concat([data, dummies], axis=1)\n",
    "data = data[[\"dtcpb\",\"stcpb\",\"service_-\",\"Dload\",\"dmeansz\",\"service_dns\",\"smeansz\",\"Sload\",\"trans_depth\",\"sttl\",\n",
    "            \"service_ftp-data\",\"ct_ftp_cmd\",\"attack_cat\"]]\n",
    "\n",
    "data['attack_cat'] = data['attack_cat'].fillna('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fcbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {np.nan: 0, ' ': 0}\n",
    "for cols in ['ct_ftp_cmd']:\n",
    "    data[cols] = data[cols].replace(replace_dict)\n",
    "    \n",
    "replace_dict = {np.nan: 0, '0': 0}\n",
    "for cols in ['ct_ftp_cmd']:\n",
    "    data[cols] = data[cols].replace(replace_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32dc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('attack_cat',axis=1).values.astype('float32')\n",
    "y = data.attack_cat.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2111e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Variable Label\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da396edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b53063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312000, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e9f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.3,random_state=40,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dca60c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 190), (1, 225), (2, 1731), (3, 4595), (4, 2253), (5, 20062), (6, 187784), (7, 1392), (8, 150), (9, 18)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f797f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 177803), (1, 177803), (2, 177803), (3, 177803), (4, 177803), (5, 177803), (6, 187784), (7, 177803), (8, 177803), (9, 177803)]\n"
     ]
    }
   ],
   "source": [
    "a = 177803 #y-traine g√∂re belirlenmeli.177803\n",
    "smo = SMOTE(sampling_strategy={0:a,1:a,2:a,3:a,4:a,5:a,7:a,8:a,9:a},random_state=42) \n",
    "X_train, y_train = smo.fit_resample(X_train, y_train)   \n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb7c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# define the undersampling method\n",
    "undersample = NearMiss(version=1, n_neighbors=3, sampling_strategy={6:a})\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d82511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 177803), (1, 177803), (2, 177803), (3, 177803), (4, 177803), (5, 177803), (6, 177803), (7, 177803), (8, 177803), (9, 177803)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5b18e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33c5e415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 4336.719126939774\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=0.005, max_depth=10, random_state=0)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "time_end = time.time()\n",
    "train_time = time_end - time_start\n",
    "print(\"Train time:\",train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47501adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_time: 0.731665849685669\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "pred = gb_clf.predict(X_test)\n",
    "\n",
    "time_end = time.time()\n",
    "test_time = time_end - time_start\n",
    "print(\"test_time:\",test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bc6e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.05      0.67      0.09        81\n",
      "      Backdoor       0.04      0.11      0.06        97\n",
      "           DoS       0.25      0.13      0.17       742\n",
      "      Exploits       0.78      0.48      0.59      1969\n",
      "       Fuzzers       0.41      0.73      0.52       966\n",
      "       Generic       1.00      0.97      0.99      8598\n",
      "        Normal       1.00      0.99      0.99     80479\n",
      "Reconnaissance       0.83      0.81      0.82       597\n",
      "     Shellcode       0.10      0.55      0.17        64\n",
      "         Worms       0.00      0.00      0.00         7\n",
      "\n",
      "      accuracy                           0.96     93600\n",
      "     macro avg       0.44      0.54      0.44     93600\n",
      "  weighted avg       0.98      0.96      0.97     93600\n",
      "\n",
      "acc: 96.2638888888889\n",
      "pre: 97.9154946475697\n",
      "DR=recall: 96.2638888888889\n",
      "f1: 96.91050270018397\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Analysis','Backdoor','DoS','Exploits','Fuzzers','Generic','Normal','Reconnaissance','Shellcode','Worms']\n",
    "acc = metrics.accuracy_score(y_test,pred) * 100\n",
    "f1 = metrics.f1_score(y_test, pred,average='weighted')* 100\n",
    "pre = metrics.precision_score(y_test, pred, labels=None, pos_label=1, average='weighted') * 100 #DR\n",
    "recall = metrics.recall_score(y_test, pred, labels=None, pos_label=1, average='weighted', sample_weight=None) * 100\n",
    "\n",
    "print(classification_report(y_test,pred,target_names=target_names))\n",
    "print(\"acc:\",acc)\n",
    "print(\"pre:\",pre)\n",
    "print(\"DR=recall:\",recall)\n",
    "print(\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a9a7db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5925925925925926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "FAR = FP / (FP + TN)\n",
    "print(FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a59661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060735f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ea004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2677e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485131c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#hyperparameter tuning\\nimport hyperopt\\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\\nfrom hyperopt.pyll import scope, as_apply\\n\\nspace={ \\'max_depth\\': scope.int(hp.uniform(\\'max_depth\\', 1, 11)),\\n        \\'learning_rate\\': hp.loguniform(\\'learning_rate\\', np.log(0.0001), np.log(0.5)) - 0.0001,\\n        \\'subsample\\':hp.uniform(\\'subsample\\',0.5,1),\\n        \\'ccp_alpha\\' : hp.loguniform(\\'ccp_alpha\\', np.log(0.0001), np.log(1)) - 0.0001,\\n        \\'n_estimators\\': scope.int(hp.quniform(\\'n_estimators\\', 100, 6000, 200)),\\n      }\\n\\n# Classifier:\\ndef hyperparameter_tuning(space):\\n    model = GradientBoostingClassifier(\\n                              max_depth = space[\\'max_depth\\'],\\n                              learning_rate=space[\\'learning_rate\\'],\\n                              n_estimators =space[\\'n_estimators\\'],\\n                              ccp_alpha = space[\\'ccp_alpha\\'],\\n                              subsample=space[\\'subsample\\'],\\n                              verbose=2\\n                              )\\n    \\n    evaluation = [( X_train, y_train), ( X_test, y_test)]\\n    \\n    model.fit(X_train, y_train)\\n\\n    pred = model.predict(X_test)\\n    accuracy = accuracy_score(y_test, pred>0.5)\\n    print (\"SCORE:\", accuracy)\\n    #change the metric if you like\\n    return {\\'loss\\': -accuracy, \\'status\\': STATUS_OK, \\'model\\': model}\\n\\ntrials = Trials()\\nbest = fmin(fn=hyperparameter_tuning,\\n            space=space,\\n            algo=tpe.suggest,\\n            max_evals=1,\\n            trials=trials)\\n\\nprint(best)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#hyperparameter tuning\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope, as_apply\n",
    "\n",
    "space={ 'max_depth': scope.int(hp.uniform('max_depth', 1, 11)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.5)) - 0.0001,\n",
    "        'subsample':hp.uniform('subsample',0.5,1),\n",
    "        'ccp_alpha' : hp.loguniform('ccp_alpha', np.log(0.0001), np.log(1)) - 0.0001,\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 100, 6000, 200)),\n",
    "      }\n",
    "\n",
    "# Classifier:\n",
    "def hyperparameter_tuning(space):\n",
    "    model = GradientBoostingClassifier(\n",
    "                              max_depth = space['max_depth'],\n",
    "                              learning_rate=space['learning_rate'],\n",
    "                              n_estimators =space['n_estimators'],\n",
    "                              ccp_alpha = space['ccp_alpha'],\n",
    "                              subsample=space['subsample'],\n",
    "                              verbose=2\n",
    "                              )\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    #change the metric if you like\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=1,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2198f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6650be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEWMODELBESTPARAMETERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52f429a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(n_estimators=1600, learning_rate=0.005, max_depth=3.34, subsample=0.93,\n",
    "                                   ccp_alpha=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71954a25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7faffcc8e94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \"\"\"\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "time_end = time.time()\n",
    "train_time = time_end - time_start\n",
    "print(\"Train time:\",train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "pred = gb_clf.predict(X_test)\n",
    "\n",
    "time_end = time.time()\n",
    "test_time = time_end - time_start\n",
    "print(\"test_time:\",test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Analysis','Backdoor','DoS','Exploits','Fuzzers','Generic','Normal','Reconnaissance','Shellcode','Worms']\n",
    "acc = metrics.accuracy_score(y_test,pred) * 100\n",
    "f1 = metrics.f1_score(y_test, pred,average='weighted')* 100\n",
    "pre = metrics.precision_score(y_test, pred, labels=None, pos_label=1, average='weighted') * 100 #DR\n",
    "recall = metrics.recall_score(y_test, pred, labels=None, pos_label=1, average='weighted', sample_weight=None) * 100\n",
    "\n",
    "print(classification_report(y_test,pred,target_names=target_names))\n",
    "print(\"acc:\",acc)\n",
    "print(\"pre:\",pre)\n",
    "print(\"DR=recall:\",recall)\n",
    "print(\"f1:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "TP = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TN = cm[1][1]\n",
    "\n",
    "FAR = FP / (FP + TN)\n",
    "print(FAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d4bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1eba53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485500d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e874a850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
